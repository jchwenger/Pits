---
layout: post
title: Max Woolf RNN 
category: lore
permalink: /lore/max-woolf/
---

Thanks to [Sabrina Recoule Quang](http://recoulesquang.com/), also in the course, I discovered Max Woolf's repo for neural text generation (using LSTMs). The project in built in Keras/TensorFlow. This will certainly be a stepping stone for my study of these networks and text generatio in general. The goal is clear: make experiments generating texts, but also, hopefully soon, pick apart the code and gradually acquire the skills to build such networks myself.

- the [repo](https://github.com/minimaxir/textgenrnn);
- the [Google Colaboratory notebook](https://drive.google.com/file/d/1mMKGnVxirJnqDViH7BDJxFqWrsXlPSoK/view), and [my copy](https://drive.google.com/open?id=1eymxSyGlPQfKl0zCa_Jdt8nuDQ_WXXDs);
- his [walkthrough](https://minimaxir.com/2018/05/text-neural-networks/) and accompanying Youtube tutorial:

<div class="video-container">
<iframe max-width="100%" height="auto" src="https://www.youtube.com/embed/RW7mP6BfZuY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
</div>

&nbsp;

He is himself, however, a student of [Karpathy](https://twitter.com/karpathy)'s, whose [char-rnn model](https://github.com/karpathy/char-rnn) is the foundation of Woolf's project.

The transition from Karpathy's code into TensorFlow is already a well-trodden path, see [here](https://r2rt.com/recurrent-neural-networks-in-tensorflow-ii.html), [here](https://github.com/sherjilozair/char-rnn-tensorflow), [here](https://github.com/crazydonkey200/tensorflow-char-rnn) and [there](https://github.com/sherjilozair/char-rnn-tensorflow). I'm assuming that [Parag Mital's Char RNN model](https://github.com/pkmital/pycadl/blob/577931dfffdd7cecbcb565c84a470aca12d2b214/cadl/charrnn.py), available in his Kadenze course, is also based on the same architecture.

