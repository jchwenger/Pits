---
layout: post
title: Datashader (plotting big data)
category: lore
permalink: /lore/datashader/
---

Whilst working on [visualisations for my WordSquares project](https://github.com/jchwenger/WordSquaresAI), I encountered problems due to the size of the dataset I wanted to plot. Digging into the [Bokeh library](https://bokeh.pydata.org/en/latest/) I found out about the [Datashader library](http://datashader.org/) that specialises in large datasets (e.g. billions of points). 

<div class="video-container">
<iframe max-width="100%" height="auto" src="https://www.youtube.com/embed/6m3CFbKmK_c" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
</div>

<p>&nbsp;</p>

For further reference, an introduction to Bokeh:

<div class="video-container">
<iframe max-width="100%" height="auto" src="https://www.youtube.com/embed/9FlUFLmaWvY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
</div>

<p>&nbsp;</p>

As well as another presentation including various libraries, Bokeh, Datashader, and others, to deal with large dataset representations:

<div class="video-container">
<iframe max-width="100%" height="auto" src="https://www.youtube.com/embed/8Jktm-Imt-I" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
</div>

<p>&nbsp;</p>

Another tool that could prove useful for working with multidimensional labelled datasets (used in the introduction to Datashader above), where Pandas only work for higher dimensions:

<div class="video-container">
<iframe max-width="100%" height="auto" src="https://www.youtube.com/embed/X0pAhJgySxk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
</div>
